{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d82c845-d593-4552-b111-6d75fa9db9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fedn.utils.helpers.helpers import get_helper, save_metadata, save_metrics\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel, PeftConfig\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd16a9cc-bcbf-4997-af20-bf9936408902",
   "metadata": {},
   "outputs": [],
   "source": [
    "HELPER_MODULE = 'numpyhelper'\n",
    "helper = get_helper(HELPER_MODULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad90453f-c553-4106-8be0-8fb3dd0484d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model():\n",
    "    peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "    peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                        '/Users/nash/Project/peft/peft-dialogue-summary-checkpoint-local', \n",
    "                                        torch_dtype=torch.bfloat16,\n",
    "                                        is_trainable=False)\n",
    "    return peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40368dfa-d6e5-419b-a75a-c9819cfbbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(model_path):\n",
    "    \"\"\" Load model parameters from file and populate model.\n",
    "\n",
    "    param model_path: The path to load from.\n",
    "    :type model_path: str\n",
    "    :return: The loaded model.\n",
    "    :rtype: torch.nn.Module\n",
    "    \"\"\"\n",
    "    parameters_np = helper.load(model_path)\n",
    "    model = compile_model()\n",
    "    params_dict = zip(model.state_dict().keys(), parameters_np)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f567bff9-b72b-4bf7-a221-6ea28110f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_model_path = '/Users/nash/Downloads/147c5fce-6219-4e17-a8cc-763ad9bd4028'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549dfa3c-6fdc-4c2a-96cf-ed00f6fa7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fedn_model = load_parameters(in_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8de4122-5d3c-409a-aa3b-f952f6915f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#dataset\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f9af99e-8907-4811-a360-3f57ff4df97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base model\n",
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3562809a-81e8-44e6-9d9e-adb87de48a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "original_model_summaries = []\n",
    "#instruct_model_summaries = []\n",
    "fedn_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "    \n",
    "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    #instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    #instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    fedn_model_outputs = fedn_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "    fedn_model_text_output = tokenizer.decode(fedn_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    original_model_summaries.append(original_model_text_output)\n",
    "    #instruct_model_summaries.append(instruct_model_text_output)\n",
    "    fedn_model_summaries.append(fedn_model_text_output)\n",
    "\n",
    "#zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
    "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, fedn_model_summaries))\n",
    " \n",
    "#df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'fedn_model_summaries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26bc8648-231d-4ff4-ba75-3247f314e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>original_model_summaries</th>\n",
       "      <th>fedn_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "      <td>#Person1#: I need to take a dictation for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "      <td>Masha and Hero are getting divorced.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
       "      <td>#Person1#: Happy birthday, Brian. #Person2#: I...</td>\n",
       "      <td>#Person1#: Happy birthday, Brian. #Person2#: I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  In order to prevent employees from wasting tim...   \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
       "3  #Person2# arrives late because of traffic jam....   \n",
       "4  #Person2# decides to follow #Person1#'s sugges...   \n",
       "5  #Person2# complains to #Person1# about the tra...   \n",
       "6  #Person1# tells Kate that Masha and Hero get d...   \n",
       "7  #Person1# tells Kate that Masha and Hero are g...   \n",
       "8  #Person1# and Kate talk about the divorce betw...   \n",
       "9  #Person1# and Brian are at the birthday party ...   \n",
       "\n",
       "                            original_model_summaries  \\\n",
       "0     #Person1#: I need to take a dictation for you.   \n",
       "1     #Person1#: I need to take a dictation for you.   \n",
       "2     #Person1#: I need to take a dictation for you.   \n",
       "3  The traffic jam at the Carrefour intersection ...   \n",
       "4  The traffic jam at the Carrefour intersection ...   \n",
       "5  The traffic jam at the Carrefour intersection ...   \n",
       "6               Masha and Hero are getting divorced.   \n",
       "7               Masha and Hero are getting divorced.   \n",
       "8               Masha and Hero are getting divorced.   \n",
       "9  #Person1#: Happy birthday, Brian. #Person2#: I...   \n",
       "\n",
       "                                fedn_model_summaries  \n",
       "0     #Person1#: I need to take a dictation for you.  \n",
       "1     #Person1#: I need to take a dictation for you.  \n",
       "2     #Person1#: I need to take a dictation for you.  \n",
       "3  The traffic jam at the Carrefour intersection ...  \n",
       "4  The traffic jam at the Carrefour intersection ...  \n",
       "5  The traffic jam at the Carrefour intersection ...  \n",
       "6               Masha and Hero are getting divorced.  \n",
       "7               Masha and Hero are getting divorced.  \n",
       "8               Masha and Hero are getting divorced.  \n",
       "9  #Person1#: Happy birthday, Brian. #Person2#: I...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655b8249-0bcd-4ba2-a830-370df3ff0dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.23966940079036853, 'rouge2': 0.11484057971014493, 'rougeL': 0.21586618876941455, 'rougeLsum': 0.21758185139233527}\n",
      "FEDN MODEL:\n",
      "{'rouge1': 0.2437953036915803, 'rouge2': 0.11657459505541348, 'rougeL': 0.22006717130387343, 'rougeLsum': 0.2218015017882039}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "\n",
    "fedn_model_results = rouge.compute(\n",
    "    predictions=fedn_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(fedn_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "# print('INSTRUCT MODEL:')\n",
    "# print(instruct_model_results)\n",
    "print('FEDN MODEL:')\n",
    "print(fedn_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94161c76-fef7-4fff-9a13-5e051dd92084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "results = pd.read_csv(\"/Users/nash/Project/peft/dialogue-summary-training-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "437da9a0-c802-4b60-8aa1-b0e9a1bcfd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Unnamed: 0                1500 non-null   int64 \n",
      " 1   human_baseline_summaries  1500 non-null   object\n",
      " 2   original_model_summaries  1500 non-null   object\n",
      " 3   instruct_model_summaries  1500 non-null   object\n",
      " 4   peft_model_summaries      1500 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2df6be8-4887-45df-bb8c-b0543ace8a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.2331453024822976, 'rouge2': 0.07621937454368599, 'rougeL': 0.20148301431607618, 'rougeLsum': 0.2013860606897664}\n",
      "FEDN MODEL:\n",
      "{'rouge1': 0.4081267958884861, 'rouge2': 0.16370094839971364, 'rougeL': 0.3251047913173757, 'rougeLsum': 0.32527800803146933}\n"
     ]
    }
   ],
   "source": [
    "human_baseline_summaries = results['human_baseline_summaries'].values\n",
    "original_model_summaries = results['original_model_summaries'].values\n",
    "fedn_model_summaries = results['peft_model_summaries'].values\n",
    "\n",
    "original_model_results = rouge.compute(\n",
    "    predictions=original_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "\n",
    "fedn_model_results = rouge.compute(\n",
    "    predictions=fedn_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(fedn_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results)\n",
    "# print('INSTRUCT MODEL:')\n",
    "# print(instruct_model_results)\n",
    "print('FEDN MODEL:')\n",
    "print(fedn_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af71b450-1db2-47ab-80e9-8b7e03401251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute percentage improvement of FEDN MODEL over ORIGINAL MODEL\n",
      "rouge1: 17.50%\n",
      "rouge2: 8.75%\n",
      "rougeL: 12.36%\n",
      "rougeLsum: 12.39%\n"
     ]
    }
   ],
   "source": [
    "print(\"Absolute percentage improvement of FEDN MODEL over ORIGINAL MODEL\")\n",
    "\n",
    "improvement = (np.array(list(fedn_model_results.values())) - np.array(list(original_model_results.values())))\n",
    "for key, value in zip(fedn_model_results.keys(), improvement):\n",
    "    print(f'{key}: {value*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae971a08-619b-47c9-b9cf-cfe349ba8b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (peft)",
   "language": "python",
   "name": "peft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
