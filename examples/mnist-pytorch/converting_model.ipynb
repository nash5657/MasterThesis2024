{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b59d363b-f18f-492e-956d-f2b0885bad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf99f8a-9c41-4e01-a5dc-3c8cafd7072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \n",
    "                                       '/Users/nash/Project/peft/peft-dialogue-summary-checkpoint-local/', \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a1c30f7-eb26-4894-8c79-753c2b426436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 251116800 || trainable%: 0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(peft_model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b447c1-4cf7-4a4e-9e2e-928df064da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedn.utils.helpers.helpers import get_helper, save_metadata, save_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d698a465-8143-48c5-96c4-c3d486c25277",
   "metadata": {},
   "outputs": [],
   "source": [
    "HELPER_MODULE = 'numpyhelper'\n",
    "helper = get_helper(HELPER_MODULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019e5010-2cc9-4e27-9e65-991e08a82e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameters(model, out_path):\n",
    "    \"\"\" Save model paramters to file.\n",
    "\n",
    "    :param model: The model to serialize.\n",
    "    :type model: torch.nn.Module\n",
    "    :param out_path: The path to save to.\n",
    "    :type out_path: str\n",
    "    \"\"\"\n",
    "    #np.set_bfloat16_enabled(True) \n",
    "    np.\n",
    "    parameters_np = [val.float().cpu().numpy() for _, val in model.state_dict().items()]\n",
    "    helper.save(parameters_np, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a692521-b1da-4cfa-9a18-8144a831217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(out_path='./compute_package/seed.npz'):\n",
    "    \"\"\" Initialize seed model and save it to file.\n",
    "\n",
    "    :param out_path: The path to save the seed model to.\n",
    "    :type out_path: str\n",
    "    \"\"\"\n",
    "    # Init and save\n",
    "    model = peft_model\n",
    "    save_parameters(model, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc4c7464-3cb8-4434-ae6a-66d5a5b7c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff2cae8-84bd-4af3-bef3-f251598635bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(model_path):\n",
    "    \"\"\" Load model parameters from file and populate model.\n",
    "\n",
    "    param model_path: The path to load from.\n",
    "    :type model_path: str\n",
    "    :return: The loaded model.\n",
    "    :rtype: torch.nn.Module\n",
    "    \"\"\"\n",
    "    model = compile_model()\n",
    "    parameters_np = helper.load(model_path)\n",
    "\n",
    "    params_dict = zip(model.state_dict().keys(), parameters_np)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d2b95-092f-424a-b566-5ff43a44608b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (peft)",
   "language": "python",
   "name": "peft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
