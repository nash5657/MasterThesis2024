{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d401d9c-897b-4cba-b846-92ce7d9e5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "\n",
    "import docker\n",
    "import fire\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, AutoModelForCausalLM\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import peft\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel, PeftConfig\n",
    "\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import T5Config\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "\n",
    "from fedn.utils.helpers.helpers import get_helper, save_metadata, save_metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80b9938-8b82-45c8-bc96-03c68254cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "HELPER_MODULE = 'numpyhelper'\n",
    "helper = get_helper(HELPER_MODULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c54348c-f44e-4ba2-b7fa-01fc9b96bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(model_path):\n",
    "    \"\"\" Load model parameters from file and populate model.\n",
    "\n",
    "    param model_path: The path to load from.\n",
    "    :type model_path: str\n",
    "    :return: The loaded model.\n",
    "    :rtype: torch.nn.Module\n",
    "    \"\"\"\n",
    "    parameters_np = helper.load(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "    params_dict = zip(model.state_dict().keys(), parameters_np)\n",
    "    state_dict = collections.OrderedDict({key: torch.tensor(x) for key, x in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36422259-bbac-41ca-807d-2361d357262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d8b5fe-76e8-4ddc-86db-7fff34440221",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_model_path = '/Users/nash/Downloads/Models/2c_4e_10/0f09c020-c528-4e0b-98c9-96c16b08e079'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1d09cb-a69f-44ed-a2e5-421a3f0c2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = load_parameters(in_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993b7fcf-d5be-49db-822a-caf7c4e1e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/Users/nash/Project/fedn/fedn/examples/mnist-pytorch/rouge_dataset.csv\")\n",
    "dialogues = dataset['dialogue'][0:50]\n",
    "human_baseline_summaries = dataset['summary'][0:50]\n",
    "\n",
    "    \n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "        prompt = f\"\"\"\n",
    "    Summarize the following conversation.\n",
    "\n",
    "    {dialogue}\n",
    "\n",
    "    Summary: \"\"\"\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
    "        peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        \n",
    "        peft_model_summaries.append(peft_model_text_output)\n",
    "\n",
    "     \n",
    "    # Evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "peft_model_results = rouge.compute(\n",
    "        predictions=peft_model_summaries,\n",
    "        references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "        use_aggregator=True,\n",
    "        use_stemmer=True,\n",
    ")\n",
    "    # JSON schema\n",
    "report = {\n",
    "        \"rouge1\": peft_model_results[\"rouge1\"],\n",
    "        \"rouge2\": peft_model_results[\"rouge2\"],\n",
    "        \"rougeL\": peft_model_results[\"rougeL\"],\n",
    "        \"rougeLsum\": peft_model_results[\"rougeLsum\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a4978b-df5e-422c-b249-cff4fa5a3f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.1789229999834666,\n",
       " 'rouge2': 0.04065469943744764,\n",
       " 'rougeL': 0.12541153850188136,\n",
       " 'rougeLsum': 0.1256964182458587}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d773bf10-d34e-4be0-8d69-09e8b7c24880",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dd9dfe8-7cff-41b1-8227-b7d112b4332d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9866422-b0fa-47f7-93e1-1369fe2213be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fedn)",
   "language": "python",
   "name": "fedn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
